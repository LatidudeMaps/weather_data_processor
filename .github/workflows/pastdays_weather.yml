name: Historical Weather Data

on:
  workflow_dispatch:
    inputs:
      days_back:
        description: "How many past days of data to fetch"
        required: true
        default: "3"

permissions:
  contents: write

jobs:
  process-historical-weather-data:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y gdal-bin python3-gdal curl jq

      - name: Process historical weather data
        run: |
          #!/bin/bash
          set -euo pipefail

          DAYS_BACK=${{ github.event.inputs.days_back }}
          NOW_TS=$(date -u +%s)

          echo "Processing weather data for the past $DAYS_BACK days..."
          mkdir -p raw-data processed-data

          for offset in $(seq 0 $((DAYS_BACK-1))); do
            gfs_date=$(date -u -d "-$offset day" +%Y%m%d)

            for gfs_run in 00 06 12 18; do
              run_time="${gfs_date} ${gfs_run}:00"
              run_ts=$(date -u -d "$run_time" +%s)

              # Skip if run is less than 5h old (data not reliably available yet)
              if (( NOW_TS - run_ts < 18000 )); then
                echo "Skipping ${gfs_date} ${gfs_run}Z (not available yet)"
                continue
              fi

              echo "Processing ${gfs_date} ${gfs_run}Z run..."

              cd raw-data

              # Helper to download with check
              download_grib() {
                local var=$1
                local lev=$2
                local outfile=$3
                local url="https://nomads.ncep.noaa.gov/cgi-bin/filter_gfs_0p25.pl?file=gfs.t${gfs_run}z.pgrb2.0p25.f000&var_${var}=on&lev_${lev}=on&dir=%2Fgfs.${gfs_date}%2F${gfs_run}%2Fatmos"
                curl -s -f -o "$outfile" "$url" || true
                if [[ ! -s "$outfile" ]]; then
                  echo "Failed to fetch $outfile"
                  rm -f "$outfile"
                fi
              }

              # Download datasets
              download_grib "UGRD" "10_m_above_ground" "wind_u_${gfs_date}_${gfs_run}z.grib"
              download_grib "VGRD" "10_m_above_ground" "wind_v_${gfs_date}_${gfs_run}z.grib"
              download_grib "TCDC" "entire_atmosphere" "cloud_${gfs_date}_${gfs_run}z.grib"
              download_grib "TMP"  "2_m_above_ground"  "temp_${gfs_date}_${gfs_run}z.grib"
              download_grib "REFC" "entire_atmosphere" "reflectivity_${gfs_date}_${gfs_run}z.grib"

              cd ..

              # --- Process to PNG (single-line commands to avoid YAML line-continuation pitfalls) ---

              # Wind (WeatherLayers GL format: R=U, G=V, B=V duplicate)
              if [[ -s raw-data/wind_u_${gfs_date}_${gfs_run}z.grib && -s raw-data/wind_v_${gfs_date}_${gfs_run}z.grib ]]; then
                echo "Processing wind data for WeatherLayers GL..."
                
                # Create VRT with U, V, V structure as per WeatherLayers GL docs
                gdalbuildvrt -separate raw-data/wind_${gfs_date}_${gfs_run}z.vrt \
                  raw-data/wind_u_${gfs_date}_${gfs_run}z.grib \
                  raw-data/wind_v_${gfs_date}_${gfs_run}z.grib \
                  raw-data/wind_v_${gfs_date}_${gfs_run}z.grib
                
                # Calculate actual min/max values from both U and V components
                echo "Calculating wind data statistics..."
                u_stats=$(gdalinfo -stats raw-data/wind_u_${gfs_date}_${gfs_run}z.grib | grep -E "Minimum=|Maximum=" | head -2)
                v_stats=$(gdalinfo -stats raw-data/wind_v_${gfs_date}_${gfs_run}z.grib | grep -E "Minimum=|Maximum=" | head -2)
                
                u_min=$(echo "$u_stats" | grep "Minimum=" | sed 's/.*Minimum=\([^,]*\).*/\1/')
                u_max=$(echo "$u_stats" | grep "Maximum=" | sed 's/.*Maximum=\([^,]*\).*/\1/')
                v_min=$(echo "$v_stats" | grep "Minimum=" | sed 's/.*Minimum=\([^,]*\).*/\1/')
                v_max=$(echo "$v_stats" | grep "Maximum=" | sed 's/.*Maximum=\([^,]*\).*/\1/')
                
                # Find overall min and max across both components
                overall_min=$(echo "$u_min $v_min" | tr ' ' '\n' | sort -n | head -1)
                overall_max=$(echo "$u_max $v_max" | tr ' ' '\n' | sort -n | tail -1)
                
                echo "Wind data range: [$overall_min, $overall_max] m/s"
                
                # Convert to PNG using actual data range
                gdal_translate -ot Byte -scale $overall_min $overall_max 0 255 -of PNG \
                  raw-data/wind_${gfs_date}_${gfs_run}z.vrt \
                  processed-data/wind_${gfs_date}_${gfs_run}z.png
                
                # Store min/max values for metadata
                echo "{\"wind_min\": $overall_min, \"wind_max\": $overall_max}" > processed-data/wind_stats_${gfs_date}_${gfs_run}z.json
                
                # Clean up VRT
                rm -f raw-data/wind_${gfs_date}_${gfs_run}z.vrt
              fi

              # Cloud cover (%)
              if [[ -s raw-data/cloud_${gfs_date}_${gfs_run}z.grib ]]; then
                gdal_translate -ot Byte -scale 0 100 0 255 -of PNG raw-data/cloud_${gfs_date}_${gfs_run}z.grib processed-data/cloud_${gfs_date}_${gfs_run}z.png
              fi

              # Temperature (K -> fixed scale to PNG; DO NOT CHANGE as requested)
              if [[ -s raw-data/temp_${gfs_date}_${gfs_run}z.grib ]]; then
                gdal_translate \
                  -ot Byte \
                  -scale -60 52 0 255 \
                  -of PNG \
                  raw-data/temp_${gfs_date}_${gfs_run}z.grib \
                  processed-data/temp_${gfs_date}_${gfs_run}z.png
              fi

              # Composite reflectivity (dBZ)
              if [[ -s raw-data/reflectivity_${gfs_date}_${gfs_run}z.grib ]]; then
                gdal_translate -ot Byte -scale 0 60 0 255 -of PNG raw-data/reflectivity_${gfs_date}_${gfs_run}z.grib processed-data/reflectivity_${gfs_date}_${gfs_run}z.png
              fi

            done
          done

      - name: Commit and push processed data
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add processed-data/
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update historical weather data: $(date -u +%Y-%m-%d_%H:%M)Z"
            git push
          fi

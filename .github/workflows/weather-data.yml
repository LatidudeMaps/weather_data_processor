name: Process Weather Data

on:
  schedule:
    # Run every 6 hours at 00:30, 06:30, 12:30, 18:30 UTC
    - cron: '30 */6 * * *'
  workflow_dispatch:  # Allow manual triggering
    inputs:
      forecast_hour:
        description: 'Forecast hour (000-384)'
        required: false
        default: '000'
        type: string

permissions:
  contents: write

jobs:
  process-grib-data:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y gdal-bin python3-gdal curl jq
          
          # Verify GDAL installation
          gdalinfo --version
          
      - name: Get current GFS run info
        id: gfs-info
        run: |
          # Get current date and determine the latest available GFS run
          CURRENT_HOUR=$(date -u +%H)
          
          if [ $CURRENT_HOUR -ge 18 ]; then
            GFS_RUN="18"
          elif [ $CURRENT_HOUR -ge 12 ]; then
            GFS_RUN="12" 
          elif [ $CURRENT_HOUR -ge 6 ]; then
            GFS_RUN="06"
          else
            GFS_RUN="00"
          fi
          
          # Use yesterday's date if current hour is before 6 UTC
          if [ $CURRENT_HOUR -lt 6 ]; then
            GFS_DATE=$(date -u -d "yesterday" +%Y%m%d)
          else
            GFS_DATE=$(date -u +%Y%m%d)
          fi
          
          echo "gfs_date=$GFS_DATE" >> $GITHUB_OUTPUT
          echo "gfs_run=$GFS_RUN" >> $GITHUB_OUTPUT
          echo "Processing GFS data for date: $GFS_DATE, run: ${GFS_RUN}Z"

      - name: Download GFS GRIB data
        run: |
          GFS_DATE=${{ steps.gfs-info.outputs.gfs_date }}
          GFS_RUN=${{ steps.gfs-info.outputs.gfs_run }}
          FORECAST_HOUR="${{ github.event.inputs.forecast_hour || '000' }}"
          
          # Create directory for raw data
          mkdir -p raw-data
          cd raw-data
          
          echo "Downloading GFS data for ${GFS_DATE}/${GFS_RUN}Z, forecast hour: ${FORECAST_HOUR}"
          
          # Download U component of wind at 10m above ground
          echo "Downloading U wind component..."
          curl -f -o "wind_u_${FORECAST_HOUR}.grib" \
            "https://nomads.ncep.noaa.gov/cgi-bin/filter_gfs_0p25.pl?file=gfs.t${GFS_RUN}z.pgrb2.0p25.f${FORECAST_HOUR}&var_UGRD=on&lev_10_m_above_ground=on&dir=%2Fgfs.${GFS_DATE}%2F${GFS_RUN}%2Fatmos" \
            || echo "Failed to download U component"
          
          # Download V component of wind at 10m above ground  
          echo "Downloading V wind component..."
          curl -f -o "wind_v_${FORECAST_HOUR}.grib" \
            "https://nomads.ncep.noaa.gov/cgi-bin/filter_gfs_0p25.pl?file=gfs.t${GFS_RUN}z.pgrb2.0p25.f${FORECAST_HOUR}&var_VGRD=on&lev_10_m_above_ground=on&dir=%2Fgfs.${GFS_DATE}%2F${GFS_RUN}%2Fatmos" \
            || echo "Failed to download V component"
            
          # Download temperature at 2m above ground (optional)
          echo "Downloading temperature..."
          curl -f -o "temp_${FORECAST_HOUR}.grib" \
            "https://nomads.ncep.noaa.gov/cgi-bin/filter_gfs_0p25.pl?file=gfs.t${GFS_RUN}z.pgrb2.0p25.f${FORECAST_HOUR}&var_TMP=on&lev_2_m_above_ground=on&dir=%2Fgfs.${GFS_DATE}%2F${GFS_RUN}%2Fatmos" \
            || echo "Failed to download temperature"
          
          # List downloaded files
          ls -la *.grib || echo "No GRIB files downloaded"

      - name: Process GRIB to WeatherLayers format
        run: |
          # Ensure processed-data directory exists
          mkdir -p processed-data
          cd raw-data
          FORECAST_HOUR="${{ github.event.inputs.forecast_hour || '000' }}"
          
          # Check if wind files exist
          if [[ -f "wind_u_${FORECAST_HOUR}.grib" && -f "wind_v_${FORECAST_HOUR}.grib" ]]; then
            echo "Processing wind data..."
            
            # Get info about the GRIB files
            echo "Wind U info:"
            gdalinfo "wind_u_${FORECAST_HOUR}.grib"
            echo "Wind V info:"  
            gdalinfo "wind_v_${FORECAST_HOUR}.grib"
            
            # Create VRT (Virtual Dataset) combining U and V components
            gdalbuildvrt -separate "wind_${FORECAST_HOUR}.vrt" "wind_u_${FORECAST_HOUR}.grib" "wind_v_${FORECAST_HOUR}.grib"
            
            # Convert to PNG format for weatherlayers-gl
            # Scale wind values from typical range [-50, 50] m/s to [0, 255]
            gdal_translate -ot Byte -scale -50 50 0 255 -of PNG "wind_${FORECAST_HOUR}.vrt" "../processed-data/wind_${FORECAST_HOUR}.png"
            
            echo "Wind data processed successfully"
          else
            echo "Wind GRIB files not found, skipping wind processing"
          fi
          
          # Process temperature if available
          if [[ -f "temp_${FORECAST_HOUR}.grib" ]]; then
            echo "Processing temperature data..."
            
            # Get temperature range (typical: 200-320 Kelvin)
            gdalinfo "temp_${FORECAST_HOUR}.grib"
            
            # Convert temperature to PNG (scale from ~200K-320K to 0-255)
            gdal_translate -ot Byte -scale 200 320 0 255 -of PNG "temp_${FORECAST_HOUR}.grib" "../processed-data/temp_${FORECAST_HOUR}.png"
            
            echo "Temperature data processed successfully"
          else
            echo "Temperature GRIB file not found, skipping temperature processing"
          fi

      - name: Generate metadata
        run: |
          GFS_DATE=${{ steps.gfs-info.outputs.gfs_date }}
          GFS_RUN=${{ steps.gfs-info.outputs.gfs_run }}
          FORECAST_HOUR="${{ github.event.inputs.forecast_hour || '000' }}"
          
          # Create metadata JSON
          cat > processed-data/metadata.json << EOF
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "gfs_date": "${GFS_DATE}",
            "gfs_run": "${GFS_RUN}",
            "forecast_hour": "${FORECAST_HOUR}",
            "bounds": [-180, -90, 180, 90],
            "layers": {
              "wind": {
                "file": "wind_${FORECAST_HOUR}.png",
                "type": "vector",
                "units": "m/s",
                "range": [-50, 50]
              },
              "temperature": {
                "file": "temp_${FORECAST_HOUR}.png", 
                "type": "scalar",
                "units": "K",
                "range": [200, 320]
              }
            }
          }
          EOF
          
          # List processed files
          echo "Generated files:"
          ls -la processed-data/

      - name: Commit and push processed data
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Add processed files
          git add processed-data/
          
          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update weather data: $(date -u +%Y-%m-%d_%H:%M)Z"
            git push
          fi

      - name: Clean up old data (keep last 7 days)
        run: |
          # Remove files older than 7 days to prevent repository bloat
          find processed-data/ -name "*.png" -mtime +7 -delete || true
          find raw-data/ -name "*.grib" -delete || true
          
          # Commit cleanup if any files were removed
          if ! git diff --exit-code processed-data/; then
            git config --local user.email "action@github.com"
            git config --local user.name "GitHub Action"
            git add processed-data/
            git commit -m "Clean up old weather data"
            git push
          fi